"""
é¡¹ç›®çº§ä»£ç åˆ†æå™¨
ç»“åˆRAGæŠ€æœ¯ï¼Œæ™ºèƒ½åˆ†æJavaé¡¹ç›®å¹¶æä¾›ä¸Šä¸‹æ–‡æ£€ç´¢
"""

import logging
import requests
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import hashlib
import json

from config.remote_ollama_config import remote_config
from .type_resolver import ProjectTypeResolver
from .signature_parser import JavaSignatureParser
from .code_analyzer import SmartCodeAnalyzer
from .external_library_mapper import external_library_mapper

logger = logging.getLogger(__name__)

class SmartProjectAnalyzer:
    """æ™ºèƒ½é¡¹ç›®åˆ†æå™¨"""
    
    def __init__(self, project_path: Path, vector_store = None, auto_analyze: bool = True):
        """
        åˆå§‹åŒ–é¡¹ç›®åˆ†æå™¨

        Args:
            project_path: é¡¹ç›®æ ¹è·¯å¾„
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°çš„
            auto_analyze: æ˜¯å¦è‡ªåŠ¨åˆ†æé¡¹ç›®ï¼ˆé»˜è®¤Trueï¼‰
        """
        self.project_path = Path(project_path)

        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
        if vector_store is None:
            from .vector_store import CodeVectorStore
            collection_name = f"project_{self._generate_project_id()}"
            self.vector_store = CodeVectorStore(collection_name=collection_name)
        else:
            self.vector_store = vector_store

        # åˆå§‹åŒ–ç±»å‹è§£æå™¨
        self.type_resolver = ProjectTypeResolver(self.project_path)

        #  æ–°å¢ï¼šåˆå§‹åŒ–æ™ºèƒ½ä»£ç åˆ†æå™¨
        self.code_analyzer = SmartCodeAnalyzer()

        self.indexed_files = set()
        self.project_stats = {
            'total_files': 0,
            'indexed_files': 0,
            'total_methods': 0,
            'total_classes': 0
        }

        # è‡ªåŠ¨åˆ†æé¡¹ç›®ï¼ˆå¦‚æœå‘é‡å­˜å‚¨ä¸ºç©ºï¼‰
        if auto_analyze and self.vector_store.collection.count() == 0:
            logger.info("å‘é‡å­˜å‚¨ä¸ºç©ºï¼Œè‡ªåŠ¨åˆ†æé¡¹ç›®...")
            self.analyze_project()
    
    def analyze_project(self, force_reindex: bool = False) -> Dict[str, Any]:
        """
        åˆ†ææ•´ä¸ªé¡¹ç›®
        
        Args:
            force_reindex: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç´¢å¼•
            
        Returns:
            é¡¹ç›®åˆ†æç»“æœ
        """
        logger.info(f"å¼€å§‹åˆ†æé¡¹ç›®: {self.project_path}")
        
        # å¦‚æœå¼ºåˆ¶é‡æ–°ç´¢å¼•ï¼Œæ¸…ç©ºç°æœ‰æ•°æ®
        if force_reindex:
            self.vector_store.clear_collection()
            self.indexed_files.clear()
        
        # æŸ¥æ‰¾Javaæ–‡ä»¶
        java_files = self._find_java_files()
        self.project_stats['total_files'] = len(java_files)
        
        logger.info(f"æ‰¾åˆ° {len(java_files)} ä¸ªJavaæ–‡ä»¶")
        
        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for java_file in java_files:
            try:
                if java_file not in self.indexed_files or force_reindex:
                    self._analyze_file(java_file)
                    self.indexed_files.add(java_file)
                    self.project_stats['indexed_files'] += 1
            except Exception as e:
                logger.error(f"åˆ†ææ–‡ä»¶å¤±è´¥ {java_file}: {e}")
        
        # è·å–æœ€ç»ˆç»Ÿè®¡
        collection_stats = self.vector_store.get_collection_stats()

        # åˆ¤æ–­åˆ†ææ˜¯å¦æˆåŠŸ
        success = (
            self.project_stats['indexed_files'] > 0 and
            collection_stats.get('document_count', 0) > 0
        )

        result = {
            'success': success,
            'project_path': str(self.project_path),
            'stats': self.project_stats,
            'collection_stats': collection_stats,
            'indexed_files_count': len(self.indexed_files)
        }

        logger.info(f"é¡¹ç›®åˆ†æå®Œæˆ: {result}")
        return result
    
    def find_relevant_context(self, target_method: str, query_description: str = None,
                            top_k: int = 5, method_signature: str = None,
                            force_reindex: bool = False) -> List[Dict]:
        """
        ä¸ºç›®æ ‡æ–¹æ³•æŸ¥æ‰¾ç›¸å…³ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬æ™ºèƒ½å‚æ•°ç±»å‹æ£€ç´¢å’Œå¯¼å…¥ç±»å®šä¹‰æ£€ç´¢

        Args:
            target_method: ç›®æ ‡æ–¹æ³•ç­¾å (package.ClassName#methodName)
            query_description: é¢å¤–çš„æŸ¥è¯¢æè¿°
            top_k: è¿”å›ç»“æœæ•°é‡
            method_signature: å®Œæ•´çš„æ–¹æ³•ç­¾åï¼ˆç”¨äºæå–å‚æ•°ç±»å‹ï¼‰
            force_reindex: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç´¢å¼•é¡¹ç›®

        Returns:
            ç›¸å…³ä¸Šä¸‹æ–‡åˆ—è¡¨
        """
        # å¦‚æœéœ€è¦å¼ºåˆ¶é‡æ–°ç´¢å¼•
        if force_reindex:
            logger.info("å¼ºåˆ¶é‡æ–°ç´¢å¼•é¡¹ç›®...")
            self.analyze_project()

        # è§£ææ–¹æ³•ç­¾å
        method_info = self._parse_method_signature(target_method)

        # æ„å»ºæŸ¥è¯¢
        queries = []

        # åŸºäºæ–¹æ³•åçš„æŸ¥è¯¢
        queries.append(method_info['method_name'])

        # åŸºäºç±»åçš„æŸ¥è¯¢
        if method_info['class_name']:
            queries.append(f"{method_info['class_name']} {method_info['method_name']}")
            # æ·»åŠ åŒä¸€ä¸ªç±»ä¸­çš„å…¶ä»–æ–¹æ³•æŸ¥è¯¢
            queries.append(method_info['class_name'])

        # ç”¨æˆ·æä¾›çš„æè¿°
        if query_description:
            queries.append(query_description)

        #  æ–°å¢ï¼šæ™ºèƒ½å‚æ•°ç±»å‹æ£€ç´¢
        if method_signature:
            param_type_queries = self._build_parameter_type_queries(method_signature)
            queries.extend(param_type_queries)

        #  æ–°å¢ï¼šè¢«æµ‹ç±»å¯¼å…¥çš„æœ¬åœ°ç±»å®šä¹‰æ£€ç´¢
        imported_class_queries = self._build_imported_class_queries(method_info['class_name'])
        queries.extend(imported_class_queries)

        #  æ–°å¢ï¼šç±»å®Œæ•´å®šä¹‰æ£€ç´¢
        class_def_queries = self._build_class_definition_queries(method_info['class_name'])
        queries.extend(class_def_queries)

        #  æ–°å¢ï¼šä¾èµ–ç±»æ£€ç´¢
        if method_info.get('method_body'):
            dependency_queries = self._build_dependency_queries(method_info['method_body'])
            queries.extend(dependency_queries)

        #  æ–°å¢ï¼šæ–¹æ³•å‚æ•°ç±»å‹æ£€ç´¢
        if method_info.get('parameters'):
            param_queries = self._build_parameter_type_queries_enhanced(method_info['parameters'])
            queries.extend(param_queries)

        # æ·»åŠ å¸¸è§çš„ç›¸å…³æ–¹æ³•åæ¨¡å¼
        method_name = method_info['method_name']
        if method_name:
            # æŸ¥æ‰¾å¯èƒ½è¢«è°ƒç”¨çš„æ–¹æ³•
            queries.append(f"highlight {method_name}")
            queries.append(f"process {method_name}")
            queries.append(f"handle {method_name}")
            # æŸ¥æ‰¾helperæ–¹æ³•
            if 'compare' in method_name.lower():
                queries.append("highlight")
                queries.append("chunk")
                queries.append("diff")

        # æ·»åŠ ä¾èµ–ç±»æŸ¥è¯¢
        # ä»æ–¹æ³•ç­¾åä¸­æå–ç±»å
        if 'ImageChunk' in target_method:
            queries.extend([
                "ImageChunk",
                "getIdentifier",
                "imageHash",
                "rectangle",
                "record ImageChunk",
                "com.example.pdfcompare.model.ImageChunk"
            ])
        if 'PdfContentByte' in target_method:
            queries.append("PdfContentByte")
        if 'BaseColor' in target_method:
            queries.append("BaseColor")
        if 'TextChunk' in target_method:
            queries.extend([
                "TextChunk",
                "record TextChunk",
                "com.example.pdfcompare.model.TextChunk"
            ])

        # é€šç”¨çš„ä¾èµ–ç±»æŸ¥è¯¢
        queries.extend([
            "record",  # æŸ¥æ‰¾recordç±»
            "model",   # æŸ¥æ‰¾modelåŒ…ä¸­çš„ç±»
            "com.example.pdfcompare.model"  # ç›´æ¥æŸ¥æ‰¾modelåŒ…
        ])
        
        # æ‰§è¡Œå¤šä¸ªæŸ¥è¯¢å¹¶åˆå¹¶ç»“æœ
        all_results = []
        seen_ids = set()

        for query in queries:
            logger.debug(f"æ‰§è¡ŒæŸ¥è¯¢: {query}")

            results = self.vector_store.search_similar_code(
                query=query,
                top_k=top_k,
                filter_metadata={'language': 'java'}  # åªæœç´¢Javaä»£ç 
            )

            # å»é‡å¹¶æ·»åŠ åˆ°ç»“æœ
            for result in results:
                result_id = result.get('id')
                if result_id and result_id not in seen_ids:
                    result['query'] = query  # è®°å½•åŒ¹é…çš„æŸ¥è¯¢
                    all_results.append(result)
                    seen_ids.add(result_id)

        #  æ–°å¢ï¼šç¡®ä¿å¯¼å…¥çš„æœ¬åœ°ç±»å®šä¹‰è¢«åŒ…å«
        all_results = self._ensure_imported_class_definitions(all_results, method_info['class_name'])

        #  æ–°å¢ï¼šç¡®ä¿recordç±»å®šä¹‰è¢«åŒ…å«
        all_results = self._ensure_record_definitions(all_results)

        #  æ–°å¢ï¼šç¡®ä¿ä¾èµ–ç±»å®šä¹‰è¢«åŒ…å«
        all_results = self._ensure_dependency_definitions(all_results, method_info)

        #  æ–°å¢ï¼šä½¿ç”¨æ™ºèƒ½ä»£ç åˆ†æå™¨å¢å¼ºä¸Šä¸‹æ–‡
        all_results = self._enhance_with_smart_analysis(all_results, method_info)

        #  æ–°å¢ï¼šæ·»åŠ å¤–éƒ¨åº“ç±»ä¿¡æ¯
        all_results = self._add_external_library_context(all_results, method_info)

        # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›top_k
        all_results.sort(key=lambda x: x.get('distance', 1.0))

        logger.info(f"ä¸º {target_method} æ‰¾åˆ° {len(all_results[:top_k])} ä¸ªç›¸å…³ä¸Šä¸‹æ–‡")
        return all_results[:top_k]
    
    def find_similar_methods(self, method_code: str, top_k: int = 3) -> List[Dict]:
        """
        æŸ¥æ‰¾ä¸ç»™å®šæ–¹æ³•ç›¸ä¼¼çš„æ–¹æ³•
        
        Args:
            method_code: æ–¹æ³•ä»£ç 
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            ç›¸ä¼¼æ–¹æ³•åˆ—è¡¨
        """
        # ä»æ–¹æ³•ä»£ç ä¸­æå–å…³é”®ä¿¡æ¯
        query = self._extract_method_keywords(method_code)
        
        results = self.vector_store.search_similar_code(
            query=query,
            top_k=top_k,
            filter_metadata={'type': 'method', 'language': 'java'}
        )
        
        logger.info(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼æ–¹æ³•")
        return results
    
    def get_class_context(self, class_name: str) -> List[Dict]:
        """
        è·å–æŒ‡å®šç±»çš„æ‰€æœ‰ä¸Šä¸‹æ–‡
        
        Args:
            class_name: ç±»å
            
        Returns:
            ç±»çš„æ‰€æœ‰æ–¹æ³•å’Œç›¸å…³ä¿¡æ¯
        """
        results = self.vector_store.search_similar_code(
            query=class_name,
            top_k=50,  # è·å–æ›´å¤šç»“æœ
            filter_metadata={'class_name': class_name, 'language': 'java'}
        )
        
        logger.info(f"è·å–ç±» {class_name} çš„ {len(results)} ä¸ªä¸Šä¸‹æ–‡é¡¹")
        return results
    
    def _find_java_files(self) -> List[Path]:
        """æŸ¥æ‰¾é¡¹ç›®ä¸­çš„æ‰€æœ‰Javaæ–‡ä»¶"""
        java_files = []
        
        # é€’å½’æŸ¥æ‰¾.javaæ–‡ä»¶
        for java_file in self.project_path.rglob("*.java"):
            # è·³è¿‡æµ‹è¯•æ–‡ä»¶å’Œæ„å»ºç›®å½•
            if self._should_include_file(java_file):
                java_files.append(java_file)
        
        return java_files
    
    def _should_include_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åŒ…å«è¯¥æ–‡ä»¶"""
        # æ’é™¤çš„ç›®å½•
        exclude_dirs = {'test', 'tests', 'target', 'build', '.git', 'node_modules'}
        
        # æ£€æŸ¥è·¯å¾„ä¸­æ˜¯å¦åŒ…å«æ’é™¤çš„ç›®å½•
        for part in file_path.parts:
            if part.lower() in exclude_dirs:
                return False
        
        # æ’é™¤æµ‹è¯•æ–‡ä»¶
        filename = file_path.name.lower()
        if 'test' in filename and filename.endswith('.java'):
            return False
        
        return True
    
    def _analyze_file(self, file_path: Path):
        """åˆ†æå•ä¸ªJavaæ–‡ä»¶"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„Javaè§£æå™¨
            from source_analysis.java_parser import JavaParser
            
            parser = JavaParser()
            parsed_class = parser.parse_file(file_path)
            
            if not parsed_class:
                logger.warning(f"æ— æ³•è§£ææ–‡ä»¶: {file_path}")
                return
            
            self.project_stats['total_classes'] += 1
            
            # ç´¢å¼•ç±»çº§åˆ«çš„ä¿¡æ¯
            class_metadata = {
                'type': 'class',
                'class_name': parsed_class.name,
                'package': parsed_class.package,
                'file_path': str(file_path.relative_to(self.project_path)),
                'language': 'java'
            }
            
            # æ·»åŠ ç±»çš„å®Œæ•´ä¿¡æ¯
            try:
                # è¯»å–å®Œæ•´çš„ç±»å®šä¹‰
                class_content = file_path.read_text(encoding='utf-8')

                # å¯¹äºç®€çŸ­çš„ç±»ï¼ˆå¦‚recordï¼‰ï¼ŒåŒ…å«å®Œæ•´å®šä¹‰
                if len(class_content) <= 500 or 'record' in class_content:
                    class_info = f"Class: {parsed_class.name}\nPackage: {parsed_class.package}\n\nFull Definition:\n{class_content}"
                else:
                    # å¯¹äºé•¿ç±»ï¼ŒåªåŒ…å«æ‘˜è¦
                    class_info = f"class {parsed_class.name} in package {parsed_class.package}"
                    if parsed_class.imports:
                        class_info += f" with imports: {', '.join(parsed_class.imports[:5])}"

                self.vector_store.add_code_snippet(class_info, class_metadata)

            except Exception as e:
                # å›é€€åˆ°ç®€å•æ‘˜è¦
                class_summary = f"class {parsed_class.name} in package {parsed_class.package}"
                if parsed_class.imports:
                    class_summary += f" with imports: {', '.join(parsed_class.imports[:5])}"
                self.vector_store.add_code_snippet(class_summary, class_metadata)
            
            # ç´¢å¼•æ¯ä¸ªæ–¹æ³•
            for method in parsed_class.methods:
                self._index_method(method, parsed_class, file_path)
                self.project_stats['total_methods'] += 1
            
            logger.debug(f"å·²ç´¢å¼•æ–‡ä»¶: {file_path}")
            
        except Exception as e:
            logger.error(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def _index_method(self, method, parsed_class, file_path: Path):
        """ç´¢å¼•å•ä¸ªæ–¹æ³•"""
        try:
            # æ„å»ºæ–¹æ³•å…ƒæ•°æ®
            metadata = {
                'type': 'method',
                'method_name': method.name,
                'class_name': parsed_class.name,
                'package': parsed_class.package,
                'file_path': str(file_path.relative_to(self.project_path)),
                'start_line': method.start_line,
                'end_line': method.end_line,
                'access_modifier': method.access_modifier,
                'language': 'java'
            }
            
            # ä½¿ç”¨æ–¹æ³•ç­¾åå’Œæ–¹æ³•ä½“ä½œä¸ºæ–‡æ¡£å†…å®¹
            method_content = f"Method: {method.signature}\n\nImplementation:\n{method.body}"
            
            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            self.vector_store.add_code_snippet(method_content, metadata)
            
        except Exception as e:
            logger.error(f"ç´¢å¼•æ–¹æ³•å¤±è´¥ {method.name}: {e}")
    
    def _parse_method_signature(self, signature: str) -> Dict[str, str]:
        """è§£ææ–¹æ³•ç­¾å"""
        if '#' in signature:
            # Javaé£æ ¼: package.ClassName#methodName
            class_part, method_name = signature.split('#', 1)
            package_parts = class_part.split('.')
            class_name = package_parts[-1] if package_parts else None
            package = '.'.join(package_parts[:-1]) if len(package_parts) > 1 else ''
        else:
            # ç®€å•æ–¹æ³•å
            method_name = signature
            class_name = None
            package = ''
        
        return {
            'method_name': method_name,
            'class_name': class_name,
            'package': package
        }
    
    def _extract_method_keywords(self, method_code: str) -> str:
        """ä»æ–¹æ³•ä»£ç ä¸­æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        keywords = []
        
        # æå–æ–¹æ³•å
        import re
        method_match = re.search(r'(?:public|private|protected)?\s*\w+\s+(\w+)\s*\(', method_code)
        if method_match:
            keywords.append(method_match.group(1))
        
        # æå–å¸¸è§çš„ç¼–ç¨‹æ¦‚å¿µ
        concepts = ['add', 'get', 'set', 'create', 'delete', 'update', 'validate', 'check', 'calculate', 'find', 'search', 'sort', 'filter']
        for concept in concepts:
            if concept.lower() in method_code.lower():
                keywords.append(concept)
        
        return ' '.join(keywords) if keywords else method_code[:100]

    def _build_parameter_type_queries(self, method_signature: str) -> List[str]:
        """
        åŸºäºæ–¹æ³•ç­¾åæ„å»ºå‚æ•°ç±»å‹æŸ¥è¯¢

        Args:
            method_signature: å®Œæ•´çš„æ–¹æ³•ç­¾å

        Returns:
            å‚æ•°ç±»å‹æŸ¥è¯¢åˆ—è¡¨
        """
        queries = []

        try:
            # æå–æ‰€æœ‰ç±»å‹ï¼ˆå‚æ•°ç±»å‹å’Œè¿”å›ç±»å‹ï¼‰
            all_types = JavaSignatureParser.extract_all_types_from_signature(method_signature)

            logger.debug(f"ä»æ–¹æ³•ç­¾åä¸­æå–çš„ç±»å‹: {all_types}")

            for type_name in all_types:
                # ä¸ºæ¯ä¸ªç±»å‹æ„å»ºå¤šç§æŸ¥è¯¢
                type_queries = self._build_queries_for_type(type_name)
                queries.extend(type_queries)

            # å»é‡
            unique_queries = list(dict.fromkeys(queries))
            logger.debug(f"æ„å»ºçš„å‚æ•°ç±»å‹æŸ¥è¯¢: {unique_queries}")

            return unique_queries

        except Exception as e:
            logger.debug(f"æ„å»ºå‚æ•°ç±»å‹æŸ¥è¯¢å¤±è´¥: {e}")
            return []

    def _build_queries_for_type(self, type_name: str) -> List[str]:
        """
        ä¸ºå•ä¸ªç±»å‹æ„å»ºæŸ¥è¯¢

        Args:
            type_name: ç±»å‹åç§°

        Returns:
            æŸ¥è¯¢åˆ—è¡¨
        """
        queries = []

        # åŸºç¡€æŸ¥è¯¢
        queries.append(type_name)

        #  å¢å¼ºï¼šç±»å£°æ˜æŸ¥è¯¢
        queries.extend([
            f"class {type_name}",
            f"public class {type_name}",
            f"record {type_name}",
            f"public record {type_name}",
            f"interface {type_name}",
            f"enum {type_name}"
        ])

        #  æ–°å¢ï¼šæ„é€ å‡½æ•°æŸ¥è¯¢
        queries.extend([
            f"constructor {type_name}",
            f"public {type_name}(",
            f"{type_name}(",
            f"new {type_name}(",
        ])

        #  æ–°å¢ï¼šæ³¨è§£æŸ¥è¯¢
        queries.extend([
            f"@RequiredArgsConstructor",
            f"@Component",
            f"@Service",
            f"@Repository",
            f"@Controller",
        ])

        # å°è¯•ä»ç±»å‹è§£æå™¨ä¸­è·å–å®Œæ•´åŒ…å
        class_info = self.type_resolver.resolve_type(type_name)
        if class_info:
            queries.append(class_info.full_qualified_name)
            queries.append(f"package {class_info.package}")

            # å¦‚æœæ˜¯recordç±»ï¼Œæ·»åŠ ç‰¹æ®ŠæŸ¥è¯¢
            if class_info.is_record:
                queries.extend([
                    f"record {type_name}",
                    f"{type_name} record",
                    "getIdentifier",  # recordç±»å¸¸è§æ–¹æ³•
                ])

        #  æ–°å¢ï¼šå¼ºåˆ¶åŒ…è·¯å¾„æŸ¥è¯¢ï¼ˆå³ä½¿ç±»å‹è§£æå™¨æ²¡æœ‰æ‰¾åˆ°ï¼‰
        queries.extend([
            f"import.*{type_name}",
            f"package.*{type_name}",
            f"{type_name}.java",
            f"class.*{type_name}.*\\{{",  # åŒ¹é…ç±»å®šä¹‰
            f"public.*{type_name}.*\\{{",
        ])

        #  æ–°å¢ï¼šå¤–éƒ¨åº“æ£€æŸ¥
        if self.external_library_mapper:
            import_stmt = self.external_library_mapper.get_import_statement(type_name)
            if import_stmt:
                queries.append(import_stmt)
                queries.append(f"import {import_stmt.split()[-1]}")

        return queries

    def _build_class_definition_queries(self, class_name: str) -> List[str]:
        """
        æ„å»ºç±»å®Œæ•´å®šä¹‰æŸ¥è¯¢

        Args:
            class_name: ç±»å

        Returns:
            ç±»å®šä¹‰æŸ¥è¯¢åˆ—è¡¨
        """
        queries = []

        #  å®Œæ•´ç±»å®šä¹‰æŸ¥è¯¢
        queries.extend([
            f"record {class_name}",
            f"class {class_name}",
            f"public class {class_name}",
            f"@Component class {class_name}",
            f"@Service class {class_name}",
            f"@Repository class {class_name}",
            f"@Controller class {class_name}",
        ])

        #  æ„é€ å‡½æ•°ç›¸å…³æŸ¥è¯¢
        queries.extend([
            f"@RequiredArgsConstructor",
            f"@AllArgsConstructor",
            f"@NoArgsConstructor",
            f"constructor {class_name}",
            f"public {class_name}(",
            f"{class_name}(",
        ])

        #  ä¾èµ–æ³¨å…¥ç›¸å…³æŸ¥è¯¢
        queries.extend([
            f"@Autowired",
            f"@Inject",
            f"private final",
            f"private {class_name}",
        ])

        return queries

    def _build_dependency_queries(self, method_implementation: str) -> List[str]:
        """
        ä»æ–¹æ³•å®ç°ä¸­æå–ä¾èµ–ç±»æŸ¥è¯¢

        Args:
            method_implementation: æ–¹æ³•å®ç°ä»£ç 

        Returns:
            ä¾èµ–æŸ¥è¯¢åˆ—è¡¨
        """
        queries = []

        if not method_implementation:
            return queries

        try:
            import re

            #  æå–æ–¹æ³•è°ƒç”¨æ¨¡å¼ï¼šobject.method()
            method_calls = re.findall(r'(\w+)\.(\w+)\s*\(', method_implementation)
            for obj, method in method_calls:
                if obj not in ['this', 'super', 'System', 'Math']:  # æ’é™¤å¸¸è§çš„éä¾èµ–è°ƒç”¨
                    queries.extend([
                        f"class {obj}",
                        f"public class {obj}",
                        f"@Component class {obj}",
                        f"public {method}",
                        f"{obj}.{method}",
                        f"void {method}",
                        f"String {method}",
                        f"int {method}",
                        f"boolean {method}",
                    ])

            #  æå–ç±»å‹å¼•ç”¨
            type_references = re.findall(r'\b([A-Z][a-zA-Z0-9]*)\b', method_implementation)
            for type_ref in set(type_references):
                if len(type_ref) > 2:  # è¿‡æ»¤æ‰å¤ªçŸ­çš„åŒ¹é…
                    queries.extend([
                        f"class {type_ref}",
                        f"record {type_ref}",
                        f"interface {type_ref}",
                        f"enum {type_ref}",
                    ])

        except Exception as e:
            logger.debug(f"æå–ä¾èµ–æŸ¥è¯¢å¤±è´¥: {e}")

        return queries

    def _build_imported_class_queries(self, class_name: str) -> List[str]:
        """
        æ„å»ºè¢«æµ‹ç±»å¯¼å…¥çš„æœ¬åœ°ç±»æŸ¥è¯¢

        Args:
            class_name: è¢«æµ‹ç±»å

        Returns:
            å¯¼å…¥ç±»æŸ¥è¯¢åˆ—è¡¨
        """
        queries = []

        if not class_name:
            return queries

        try:
            # æŸ¥æ‰¾è¢«æµ‹ç±»çš„æ–‡ä»¶
            class_info = self.type_resolver.resolve_type(class_name)
            if not class_info:
                logger.debug(f"æœªæ‰¾åˆ°ç±»ä¿¡æ¯: {class_name}")
                return queries

            # è¯»å–è¢«æµ‹ç±»æ–‡ä»¶å†…å®¹
            import os
            class_file_path = os.path.join(self.project_path, class_info.file_path)
            if not os.path.exists(class_file_path):
                logger.debug(f"ç±»æ–‡ä»¶ä¸å­˜åœ¨: {class_file_path}")
                return queries

            with open(class_file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–importè¯­å¥ä¸­çš„æœ¬åœ°ç±»
            import re
            import_pattern = r'import\s+com\.example\.pdfcompare\.(\w+)\.(\w+);'
            imports = re.findall(import_pattern, content)

            for package_part, imported_class in imports:
                # ä¸ºæ¯ä¸ªå¯¼å…¥çš„æœ¬åœ°ç±»æ„å»ºæŸ¥è¯¢
                queries.extend([
                    imported_class,
                    f"class {imported_class}",
                    f"public class {imported_class}",
                    f"record {imported_class}",
                    f"public record {imported_class}",
                    f"com.example.pdfcompare.{package_part}.{imported_class}"
                ])

                logger.debug(f"æ·»åŠ å¯¼å…¥ç±»æŸ¥è¯¢: {imported_class} from {package_part}")

        except Exception as e:
            logger.debug(f"æ„å»ºå¯¼å…¥ç±»æŸ¥è¯¢å¤±è´¥: {e}")

        return queries

    def _ensure_imported_class_definitions(self, results: List[Dict], class_name: str) -> List[Dict]:
        """
        ç¡®ä¿å¯¼å…¥çš„æœ¬åœ°ç±»å®šä¹‰è¢«åŒ…å«åœ¨ç»“æœä¸­

        Args:
            results: å½“å‰æœç´¢ç»“æœ
            class_name: è¢«æµ‹ç±»å

        Returns:
            å¢å¼ºåçš„ç»“æœåˆ—è¡¨
        """
        if not class_name:
            return results

        try:
            # æŸ¥æ‰¾è¢«æµ‹ç±»çš„å¯¼å…¥ä¿¡æ¯
            class_info = self.type_resolver.resolve_type(class_name)
            if not class_info:
                return results

            # è¯»å–è¢«æµ‹ç±»æ–‡ä»¶å†…å®¹
            import os
            class_file_path = os.path.join(self.project_path, class_info.file_path)
            if not os.path.exists(class_file_path):
                return results

            with open(class_file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–importè¯­å¥ä¸­çš„æœ¬åœ°ç±»
            import re
            import_pattern = r'import\s+com\.example\.pdfcompare\.(\w+)\.(\w+);'
            imports = re.findall(import_pattern, content)

            # æ£€æŸ¥æ¯ä¸ªå¯¼å…¥çš„ç±»æ˜¯å¦åœ¨ç»“æœä¸­æœ‰å®Œæ•´å®šä¹‰
            for package_part, imported_class in imports:
                has_definition = False

                # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¯¥ç±»çš„å®Œæ•´å®šä¹‰
                for result in results:
                    result_content = result.get('content', '')
                    if (f"class {imported_class}" in result_content or
                        f"record {imported_class}" in result_content) and \
                       len(result_content) > 100:  # ç¡®ä¿æ˜¯å®Œæ•´å®šä¹‰ï¼Œä¸åªæ˜¯å¯¼å…¥è¯­å¥
                        has_definition = True
                        break

                # å¦‚æœæ²¡æœ‰å®Œæ•´å®šä¹‰ï¼Œå°è¯•ç›´æ¥æœç´¢
                if not has_definition:
                    logger.debug(f"ç¼ºå°‘ {imported_class} çš„å®Œæ•´å®šä¹‰ï¼Œå°è¯•ç›´æ¥æœç´¢...")

                    definition_results = self.vector_store.search_similar_code(
                        query=f"class {imported_class}",
                        top_k=3,
                        filter_metadata={'language': 'java'}
                    )

                    # æ·»åŠ æ‰¾åˆ°çš„å®šä¹‰
                    for def_result in definition_results:
                        def_content = def_result.get('content', '')
                        if (f"class {imported_class}" in def_content or
                            f"record {imported_class}" in def_content) and \
                           len(def_content) > 100:
                            def_result['query'] = f"imported_class_definition_{imported_class}"
                            def_result['distance'] = 0.5  # ç»™äºˆè¾ƒé«˜ä¼˜å…ˆçº§
                            results.append(def_result)
                            logger.debug(f"æ·»åŠ äº† {imported_class} çš„å®Œæ•´å®šä¹‰")
                            break

        except Exception as e:
            logger.debug(f"ç¡®ä¿å¯¼å…¥ç±»å®šä¹‰å¤±è´¥: {e}")

        return results

    def _ensure_record_definitions(self, results: List[Dict]) -> List[Dict]:
        """
        ç¡®ä¿recordç±»çš„å®Œæ•´å®šä¹‰è¢«åŒ…å«

        Args:
            results: å½“å‰æœç´¢ç»“æœ

        Returns:
            å¢å¼ºåçš„ç»“æœåˆ—è¡¨
        """
        enhanced_results = results.copy()

        try:
            # æŸ¥æ‰¾ç»“æœä¸­æåˆ°çš„recordç±»
            record_classes = set()
            for result in results:
                content = result.get('content', '')
                metadata = result.get('metadata', {})

                # ä»å†…å®¹ä¸­æå–recordç±»å
                import re
                record_matches = re.findall(r'record\s+(\w+)', content)
                record_classes.update(record_matches)

                # ä»metadataä¸­æå–
                if metadata.get('type') == 'class' and 'record' in content:
                    class_name = metadata.get('class_name')
                    if class_name:
                        record_classes.add(class_name)

            # ä¸ºæ¯ä¸ªrecordç±»æ£€ç´¢å®Œæ•´å®šä¹‰
            for record_class in record_classes:
                record_queries = [
                    f"record {record_class}",
                    f"public record {record_class}",
                    f"{record_class} record",
                ]

                for query in record_queries:
                    additional_results = self.vector_store.search_similar_code(
                        query=query,
                        top_k=2,
                        filter_metadata={'language': 'java'}
                    )

                    for result in additional_results:
                        result_id = result.get('id')
                        if result_id and not any(r.get('id') == result_id for r in enhanced_results):
                            result['query'] = f"record_definition:{query}"
                            enhanced_results.append(result)
                            logger.debug(f"æ·»åŠ recordç±»å®šä¹‰: {record_class}")

        except Exception as e:
            logger.debug(f"ç¡®ä¿recordå®šä¹‰å¤±è´¥: {e}")

        return enhanced_results

    def _ensure_dependency_definitions(self, results: List[Dict], method_info: Dict) -> List[Dict]:
        """
        ç¡®ä¿ä¾èµ–ç±»å®šä¹‰è¢«åŒ…å«

        Args:
            results: å½“å‰æœç´¢ç»“æœ
            method_info: æ–¹æ³•ä¿¡æ¯

        Returns:
            å¢å¼ºåçš„ç»“æœåˆ—è¡¨
        """
        enhanced_results = results.copy()

        try:
            # ä»æ–¹æ³•å®ç°ä¸­æå–ä¾èµ–
            method_body = method_info.get('method_body', '')
            if not method_body:
                return enhanced_results

            import re

            # æå–å¯èƒ½çš„ä¾èµ–ç±»å
            dependency_classes = set()

            # æå–æ–¹æ³•è°ƒç”¨ä¸­çš„å¯¹è±¡å
            method_calls = re.findall(r'(\w+)\.(\w+)\s*\(', method_body)
            for obj, method in method_calls:
                if obj not in ['this', 'super', 'System', 'Math'] and obj[0].islower():
                    # å¯èƒ½æ˜¯ä¾èµ–å¯¹è±¡ï¼Œå°è¯•æ¨æ–­ç±»å
                    potential_class = obj.capitalize() + 'er' if not obj.endswith('er') else obj.capitalize()
                    dependency_classes.add(potential_class)

                    # å¸¸è§æ¨¡å¼ï¼špdfHighlighter -> PDFHighlighter
                    if 'pdf' in obj.lower():
                        dependency_classes.add('PDFHighlighter')
                    if 'highlighter' in obj.lower():
                        dependency_classes.add('PDFHighlighter')

            # ä¸ºæ¯ä¸ªä¾èµ–ç±»æ£€ç´¢å®šä¹‰
            for dep_class in dependency_classes:
                dep_queries = [
                    f"class {dep_class}",
                    f"public class {dep_class}",
                    f"@Component class {dep_class}",
                    f"@Service class {dep_class}",
                ]

                for query in dep_queries:
                    additional_results = self.vector_store.search_similar_code(
                        query=query,
                        top_k=2,
                        filter_metadata={'language': 'java'}
                    )

                    for result in additional_results:
                        result_id = result.get('id')
                        if result_id and not any(r.get('id') == result_id for r in enhanced_results):
                            result['query'] = f"dependency_definition:{query}"
                            enhanced_results.append(result)
                            logger.debug(f"æ·»åŠ ä¾èµ–ç±»å®šä¹‰: {dep_class}")

        except Exception as e:
            logger.debug(f"ç¡®ä¿ä¾èµ–å®šä¹‰å¤±è´¥: {e}")

        return enhanced_results

    def _enhance_with_smart_analysis(self, results: List[Dict], method_info: Dict) -> List[Dict]:
        """
        ä½¿ç”¨æ™ºèƒ½ä»£ç åˆ†æå™¨å¢å¼ºä¸Šä¸‹æ–‡

        Args:
            results: å½“å‰æœç´¢ç»“æœ
            method_info: æ–¹æ³•ä¿¡æ¯

        Returns:
            å¢å¼ºåçš„ç»“æœåˆ—è¡¨
        """
        enhanced_results = results.copy()

        try:
            # åˆ†æè¢«æµ‹ç±»
            class_name = method_info.get('class_name')
            if not class_name:
                return enhanced_results

            # æŸ¥æ‰¾è¢«æµ‹ç±»æ–‡ä»¶
            class_info = self.type_resolver.resolve_type(class_name)
            if not class_info:
                return enhanced_results

            import os
            class_file_path = os.path.join(self.project_path, class_info.file_path)
            if not os.path.exists(class_file_path):
                return enhanced_results

            # ä½¿ç”¨æ™ºèƒ½ä»£ç åˆ†æå™¨åˆ†æç±»
            analyzed_class = self.code_analyzer.analyze_class(class_file_path)
            if not analyzed_class:
                return enhanced_results

            logger.debug(f"æ™ºèƒ½åˆ†æç±» {class_name}: record={analyzed_class.is_record}, component={analyzed_class.is_component}")

            # ä¸ºåˆ†æç»“æœæ·»åŠ ç‰¹æ®Šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            analysis_context = {
                'id': f"smart_analysis_{class_name}",
                'content': self._format_smart_analysis(analyzed_class),
                'metadata': {
                    'type': 'smart_analysis',
                    'class_name': class_name,
                    'package': analyzed_class.package,
                    'language': 'java',
                    'is_record': analyzed_class.is_record,
                    'is_component': analyzed_class.is_component,
                },
                'distance': 0.1,  # ç»™äºˆæœ€é«˜ä¼˜å…ˆçº§
                'query': 'smart_analysis'
            }

            # å°†æ™ºèƒ½åˆ†æç»“æœæ’å…¥åˆ°ç»“æœåˆ—è¡¨çš„å¼€å¤´
            enhanced_results.insert(0, analysis_context)

            # åˆ†æä¾èµ–ç±»
            for dependency in analyzed_class.dependencies:
                dep_class_info = self.type_resolver.resolve_type(dependency)
                if dep_class_info:
                    dep_file_path = os.path.join(self.project_path, dep_class_info.file_path)
                    if os.path.exists(dep_file_path):
                        analyzed_dep = self.code_analyzer.analyze_class(dep_file_path)
                        if analyzed_dep:
                            dep_context = {
                                'id': f"smart_analysis_dep_{dependency}",
                                'content': self._format_smart_analysis(analyzed_dep),
                                'metadata': {
                                    'type': 'smart_analysis_dependency',
                                    'class_name': dependency,
                                    'package': analyzed_dep.package,
                                    'language': 'java',
                                    'is_record': analyzed_dep.is_record,
                                    'is_component': analyzed_dep.is_component,
                                },
                                'distance': 0.2,
                                'query': f'smart_analysis_dependency_{dependency}'
                            }
                            enhanced_results.append(dep_context)
                            logger.debug(f"æ·»åŠ ä¾èµ–ç±»æ™ºèƒ½åˆ†æ: {dependency}")

        except Exception as e:
            logger.debug(f"æ™ºèƒ½åˆ†æå¢å¼ºå¤±è´¥: {e}")

        return enhanced_results

    def _format_smart_analysis(self, class_info) -> str:
        """
        æ ¼å¼åŒ–æ™ºèƒ½åˆ†æç»“æœ

        Args:
            class_info: åˆ†æå¾—åˆ°çš„ç±»ä¿¡æ¯

        Returns:
            æ ¼å¼åŒ–çš„åˆ†æç»“æœ
        """
        lines = []

        # åŸºæœ¬ä¿¡æ¯
        class_type = "record" if class_info.is_record else "class"
        lines.append(f" SMART ANALYSIS: {class_type} {class_info.name}")
        lines.append(f" Package: {class_info.package}")

        # æ³¨è§£ä¿¡æ¯
        if class_info.annotations:
            lines.append(f" Annotations: {', '.join(class_info.annotations)}")

        # æ„é€ å‡½æ•°ä¿¡æ¯
        if class_info.constructors:
            for i, constructor in enumerate(class_info.constructors):
                if constructor.parameters:
                    param_str = ', '.join([f"{ptype} {pname}" for ptype, pname in constructor.parameters])
                    lines.append(f" Constructor {i+1}: {class_info.name}({param_str})")
                else:
                    lines.append(f" Constructor {i+1}: {class_info.name}() - default constructor")

                if constructor.annotations:
                    lines.append(f"   Annotations: {', '.join(constructor.annotations)}")

        # ä¾èµ–ä¿¡æ¯
        if class_info.dependencies:
            lines.append(f"ğŸ”— Dependencies: {', '.join(class_info.dependencies)}")

        # ç‰¹æ®Šæç¤º
        if class_info.is_record:
            lines.append("  RECORD CLASS: Use exact constructor parameters!")

        if class_info.is_component:
            lines.append("  SPRING COMPONENT: Use @Mock for dependencies and @InjectMocks for this class!")

        if any('@RequiredArgsConstructor' in ann for ann in class_info.annotations):
            lines.append("  LOMBOK @RequiredArgsConstructor: Cannot use no-arg constructor!")

        return '\n'.join(lines)

    def _build_parameter_type_queries_enhanced(self, parameters: List[str]) -> List[str]:
        """
        å¢å¼ºçš„å‚æ•°ç±»å‹æŸ¥è¯¢æ„å»º

        Args:
            parameters: å‚æ•°åˆ—è¡¨

        Returns:
            å‚æ•°ç±»å‹æŸ¥è¯¢åˆ—è¡¨
        """
        queries = []

        try:
            for param in parameters:
                if not param or not param.strip():
                    continue

                # æå–å‚æ•°ç±»å‹
                param_parts = param.strip().split()
                if len(param_parts) >= 2:
                    param_type = param_parts[0]

                    # å¤„ç†æ³›å‹ç±»å‹ List<ImageChunk> -> ImageChunk
                    if '<' in param_type and '>' in param_type:
                        generic_type = param_type[param_type.find('<')+1:param_type.find('>')]
                        queries.extend(self._build_queries_for_type(generic_type))
                        # åŒæ—¶æŸ¥è¯¢æ³›å‹å®¹å™¨ç±»å‹æœ¬èº«
                        base_type = param_type[:param_type.find('<')]
                        if base_type not in ['List', 'Set', 'Map', 'Collection']:
                            queries.extend(self._build_queries_for_type(base_type))

                    # å¤„ç†åŸºæœ¬ç±»å‹
                    if param_type not in ['int', 'float', 'double', 'boolean', 'String', 'List']:
                        queries.extend(self._build_queries_for_type(param_type))

                    #  æ–°å¢ï¼šå¼ºåˆ¶æŸ¥è¯¢æ‰€æœ‰å‚æ•°ç±»å‹çš„åŒ…è·¯å¾„
                    if param_type and param_type not in ['int', 'float', 'double', 'boolean', 'void']:
                        queries.extend([
                            f"package {param_type}",
                            f"import.*{param_type}",
                            f"{param_type}.java",
                        ])

        except Exception as e:
            logger.debug(f"æ„å»ºå‚æ•°ç±»å‹æŸ¥è¯¢å¤±è´¥: {e}")

        return queries

    def _add_external_library_context(self, results: List[Dict], method_info: Dict) -> List[Dict]:
        """
        æ·»åŠ å¤–éƒ¨åº“ç±»ä¸Šä¸‹æ–‡ä¿¡æ¯

        Args:
            results: å½“å‰æœç´¢ç»“æœ
            method_info: æ–¹æ³•ä¿¡æ¯

        Returns:
            å¢å¼ºåçš„ç»“æœåˆ—è¡¨
        """
        enhanced_results = results.copy()

        try:
            # ä»æ–¹æ³•ç­¾åå’Œå®ç°ä¸­æå–å¯èƒ½çš„å¤–éƒ¨åº“ç±»
            external_classes = set()

            # ä»æ–¹æ³•ç­¾åä¸­æå–
            signature = method_info.get('signature', '')
            method_body = method_info.get('method_body', '')

            # å¸¸è§çš„å¤–éƒ¨åº“ç±»æ¨¡å¼
            import re
            class_patterns = [
                r'\b(PdfContentByte)\b',
                r'\b(BaseColor)\b',
                r'\b(Rectangle)\b',
                r'\b(Color)\b',
                r'\b(List)<(\w+)>',
                r'\b(Patch)<(\w+)>',
                r'\b(Delta)\b',
                r'\b(DiffUtils)\b',
            ]

            for pattern in class_patterns:
                matches = re.findall(pattern, signature + ' ' + method_body)
                for match in matches:
                    if isinstance(match, tuple):
                        external_classes.update(match)
                    else:
                        external_classes.add(match)

            # ä¸ºæ¯ä¸ªå¤–éƒ¨åº“ç±»æ·»åŠ ä¸Šä¸‹æ–‡
            for class_name in external_classes:
                if external_library_mapper.is_external_library_class(class_name):
                    import_stmt = external_library_mapper.get_import_statement(class_name)
                    constructor_hint = external_library_mapper.get_constructor_hints(class_name)

                    context_content = f" EXTERNAL LIBRARY: {class_name}\n"
                    context_content += f" Import: {import_stmt}\n"
                    if constructor_hint:
                        context_content += f" Constructor: {constructor_hint}\n"
                    context_content += f"  This is an external library class - use exact import path!"

                    external_context = {
                        'id': f"external_lib_{class_name}",
                        'content': context_content,
                        'metadata': {
                            'type': 'external_library',
                            'class_name': class_name,
                            'package': external_library_mapper.get_package_path(class_name),
                            'language': 'java',
                            'is_external': True,
                        },
                        'distance': 0.15,  # é«˜ä¼˜å…ˆçº§
                        'query': f'external_library_{class_name}'
                    }

                    enhanced_results.append(external_context)
                    logger.debug(f"æ·»åŠ å¤–éƒ¨åº“ç±»ä¸Šä¸‹æ–‡: {class_name}")

        except Exception as e:
            logger.debug(f"æ·»åŠ å¤–éƒ¨åº“ä¸Šä¸‹æ–‡å¤±è´¥: {e}")

        return enhanced_results

    def _generate_project_id(self) -> str:
        """ç”Ÿæˆé¡¹ç›®å”¯ä¸€ID"""
        # ä½¿ç”¨é¡¹ç›®ç»å¯¹è·¯å¾„çš„å“ˆå¸Œå€¼
        project_str = str(self.project_path.absolute())
        return hashlib.md5(project_str.encode()).hexdigest()[:8]
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        collection_stats = self.vector_store.get_collection_stats()
        
        return {
            'project_path': str(self.project_path),
            'project_stats': self.project_stats,
            'vector_store_stats': collection_stats,
            'indexed_files': len(self.indexed_files)
        }
