#!/usr/bin/env python3
"""
è¿œç¨‹Ollamaä¸“é¡¹é…ç½®
é€‚ç”¨äºæœ¬åœ°å¼€å‘ + è¿œç¨‹OllamaæœåŠ¡å™¨çš„æ¶æ„
"""

import sys
import requests
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config.remote_ollama_config import remote_config

def input_remote_config():
    """è¾“å…¥è¿œç¨‹æœåŠ¡å™¨é…ç½®"""
    print("ğŸŒ è¿œç¨‹OllamaæœåŠ¡å™¨é…ç½®")
    print("="*50)
    
    # è·å–æœåŠ¡å™¨åœ°å€
    print("è¯·è¾“å…¥è¿œç¨‹OllamaæœåŠ¡å™¨ä¿¡æ¯:")
    server_host = input("ğŸŒ æœåŠ¡å™¨IPæˆ–åŸŸå: ").strip()
    if not server_host:
        print(" æœåŠ¡å™¨åœ°å€ä¸èƒ½ä¸ºç©º")
        return None
    
    # è·å–ç«¯å£
    port = input("ğŸ”Œ ç«¯å£ (é»˜è®¤11434): ").strip()
    if not port:
        port = "11434"
    
    # æ„å»ºåŸºç¡€URL
    base_url = f"http://{server_host}:{port}"
    
    print(f"\nğŸ“ è¿œç¨‹æœåŠ¡å™¨åœ°å€: {base_url}")
    
    return base_url

def detect_remote_models(base_url):
    """æ£€æµ‹è¿œç¨‹æœåŠ¡å™¨ä¸Šçš„æ¨¡å‹"""
    print(f"\n æ£€æµ‹è¿œç¨‹æœåŠ¡å™¨æ¨¡å‹...")
    
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=15)
        if response.status_code != 200:
            print(f" æ— æ³•è¿æ¥åˆ°è¿œç¨‹OllamaæœåŠ¡å™¨")
            print(f"   è¯·æ£€æŸ¥:")
            print(f"   1. æœåŠ¡å™¨åœ°å€æ˜¯å¦æ­£ç¡®: {base_url}")
            print(f"   2. Ollamaæ˜¯å¦åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šè¿è¡Œ")
            print(f"   3. é˜²ç«å¢™æ˜¯å¦å…è®¸11434ç«¯å£")
            return None
        
        models_data = response.json()
        available_models = [model.get('name', '') for model in models_data.get('models', [])]
        
        if not available_models:
            print(" è¿œç¨‹æœåŠ¡å™¨ä¸Šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹")
            return None
        
        print(f" è¿œç¨‹æœåŠ¡å™¨è¿æ¥æˆåŠŸï¼")
        print(f" æ‰¾åˆ° {len(available_models)} ä¸ªæ¨¡å‹:")
        
        # åˆ†ç±»æ˜¾ç¤ºæ¨¡å‹
        generation_models = []
        embedding_models = []
        qwen_models = []
        other_models = []
        
        for model in available_models:
            model_lower = model.lower()
            if any(x in model_lower for x in ['embed', 'embedding']):
                embedding_models.append(model)
            elif 'qwen' in model_lower:
                qwen_models.append(model)
                generation_models.append(model)
            elif any(x in model_lower for x in ['coder', 'code', 'deepseek']):
                generation_models.append(model)
            else:
                other_models.append(model)
        
        print(f"\nğŸ¤– ä»£ç ç”Ÿæˆæ¨¡å‹:")
        for model in generation_models:
            print(f"   - {model}")
        
        print(f"\nğŸ”¤ åµŒå…¥æ¨¡å‹:")
        for model in embedding_models:
            print(f"   - {model}")
        
        if other_models:
            print(f"\n å…¶ä»–æ¨¡å‹:")
            for model in other_models[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {model}")
            if len(other_models) > 5:
                print(f"   ... è¿˜æœ‰ {len(other_models) - 5} ä¸ªæ¨¡å‹")
        
        return {
            'all_models': available_models,
            'generation_models': generation_models,
            'embedding_models': embedding_models,
            'qwen_models': qwen_models
        }
        
    except requests.exceptions.RequestException as e:
        print(f" è¿æ¥è¿œç¨‹æœåŠ¡å™¨å¤±è´¥: {e}")
        print(f"   è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å™¨çŠ¶æ€")
        return None
    except Exception as e:
        print(f" æ£€æµ‹æ¨¡å‹å¼‚å¸¸: {e}")
        return None

def select_models(models_info):
    """é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹"""
    print(f"\n é€‰æ‹©æ¨¡å‹é…ç½®")
    print("="*50)
    
    generation_models = models_info['generation_models']
    embedding_models = models_info['embedding_models']
    all_models = models_info['all_models']
    
    # é€‰æ‹©ä»£ç ç”Ÿæˆæ¨¡å‹
    print(f"1. é€‰æ‹©ä»£ç ç”Ÿæˆæ¨¡å‹:")
    if generation_models:
        for i, model in enumerate(generation_models, 1):
            print(f"   {i}. {model}")
        print(f"   {len(generation_models) + 1}. æ‰‹åŠ¨è¾“å…¥æ¨¡å‹å")
        
        while True:
            choice = input(f"è¯·é€‰æ‹© (1-{len(generation_models) + 1}): ").strip()
            try:
                idx = int(choice) - 1
                if 0 <= idx < len(generation_models):
                    code_model = generation_models[idx]
                    break
                elif idx == len(generation_models):
                    code_model = input("è¯·è¾“å…¥ä»£ç ç”Ÿæˆæ¨¡å‹å: ").strip()
                    break
                else:
                    print("é€‰æ‹©æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥")
            except ValueError:
                print("è¯·è¾“å…¥æ•°å­—")
    else:
        code_model = input("è¯·è¾“å…¥ä»£ç ç”Ÿæˆæ¨¡å‹å: ").strip()
    
    # é€‰æ‹©åµŒå…¥æ¨¡å‹
    print(f"\n2. é€‰æ‹©åµŒå…¥æ¨¡å‹:")
    if embedding_models:
        for i, model in enumerate(embedding_models, 1):
            print(f"   {i}. {model}")
        print(f"   {len(embedding_models) + 1}. ä½¿ç”¨ä»£ç ç”Ÿæˆæ¨¡å‹ä½œä¸ºåµŒå…¥æ¨¡å‹")
        print(f"   {len(embedding_models) + 2}. æ‰‹åŠ¨è¾“å…¥æ¨¡å‹å")
        
        while True:
            choice = input(f"è¯·é€‰æ‹© (1-{len(embedding_models) + 2}): ").strip()
            try:
                idx = int(choice) - 1
                if 0 <= idx < len(embedding_models):
                    embed_model = embedding_models[idx]
                    break
                elif idx == len(embedding_models):
                    embed_model = code_model
                    break
                elif idx == len(embedding_models) + 1:
                    embed_model = input("è¯·è¾“å…¥åµŒå…¥æ¨¡å‹å: ").strip()
                    break
                else:
                    print("é€‰æ‹©æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥")
            except ValueError:
                print("è¯·è¾“å…¥æ•°å­—")
    else:
        print("   1. ä½¿ç”¨ä»£ç ç”Ÿæˆæ¨¡å‹ä½œä¸ºåµŒå…¥æ¨¡å‹")
        print("   2. æ‰‹åŠ¨è¾“å…¥åµŒå…¥æ¨¡å‹å")
        
        choice = input("è¯·é€‰æ‹© (1-2): ").strip()
        if choice == "2":
            embed_model = input("è¯·è¾“å…¥åµŒå…¥æ¨¡å‹å: ").strip()
        else:
            embed_model = code_model
    
    # é€‰æ‹©ä¿®å¤æ¨¡å‹ï¼ˆé€šå¸¸ä½¿ç”¨ä»£ç ç”Ÿæˆæ¨¡å‹ï¼‰
    print(f"\n3. é€‰æ‹©ä»£ç ä¿®å¤æ¨¡å‹:")
    print(f"   1. ä½¿ç”¨ä»£ç ç”Ÿæˆæ¨¡å‹ ({code_model})")
    print(f"   2. æ‰‹åŠ¨è¾“å…¥å…¶ä»–æ¨¡å‹")
    
    choice = input("è¯·é€‰æ‹© (1-2, é»˜è®¤1): ").strip()
    if choice == "2":
        fix_model = input("è¯·è¾“å…¥ä¿®å¤æ¨¡å‹å: ").strip()
    else:
        fix_model = code_model
    
    return code_model, embed_model, fix_model

def test_remote_models(base_url, code_model, embed_model):
    """æµ‹è¯•è¿œç¨‹æ¨¡å‹åŠŸèƒ½"""
    print(f"\n æµ‹è¯•è¿œç¨‹æ¨¡å‹åŠŸèƒ½...")
    
    # æµ‹è¯•ä»£ç ç”Ÿæˆ
    print(f"ğŸ’» æµ‹è¯•ä»£ç ç”Ÿæˆæ¨¡å‹: {code_model}")
    try:
        chat_request = {
            "model": code_model,
            "messages": [
                {
                    "role": "user", 
                    "content": "å†™ä¸€ä¸ªJavaæ–¹æ³•è®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œï¼Œæ–¹æ³•åadd"
                }
            ],
            "stream": False
        }
        
        chat_response = requests.post(
            f"{base_url}/api/chat",
            json=chat_request,
            timeout=60
        )
        
        if chat_response.status_code == 200:
            chat_data = chat_response.json()
            if 'message' in chat_data and 'content' in chat_data['message']:
                content = chat_data['message']['content']
                print(f"    ä»£ç ç”Ÿæˆæ­£å¸¸ï¼Œå“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«Javaä»£ç 
                if any(keyword in content for keyword in ['public', 'int', 'add', 'return']):
                    print(f"    Javaä»£ç ç”Ÿæˆè´¨é‡è‰¯å¥½")
                else:
                    print(f"    ä»£ç ç”Ÿæˆå¯èƒ½éœ€è¦ä¼˜åŒ–æç¤ºè¯")
            else:
                print(f"    ä»£ç ç”Ÿæˆå“åº”æ ¼å¼é”™è¯¯")
                return False
        else:
            print(f"    ä»£ç ç”Ÿæˆå¤±è´¥: {chat_response.status_code}")
            return False
            
    except Exception as e:
        print(f"    ä»£ç ç”Ÿæˆæµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    # æµ‹è¯•åµŒå…¥åŠŸèƒ½
    print(f"\nğŸ”¤ æµ‹è¯•åµŒå…¥æ¨¡å‹: {embed_model}")
    try:
        embed_request = {
            "model": embed_model,
            "prompt": "public int add(int a, int b) { return a + b; }"
        }
        
        embed_response = requests.post(
            f"{base_url}/api/embeddings",
            json=embed_request,
            timeout=30
        )
        
        if embed_response.status_code == 200:
            embed_data = embed_response.json()
            if 'embedding' in embed_data:
                embedding = embed_data['embedding']
                print(f"    åµŒå…¥åŠŸèƒ½æ­£å¸¸: {len(embedding)} ç»´å‘é‡")
                print(f"    å‰5ä¸ªå€¼: {[round(x, 4) for x in embedding[:5]]}")
                return True
            else:
                print(f"    åµŒå…¥å“åº”æ ¼å¼é”™è¯¯")
                return False
        else:
            print(f"    åµŒå…¥åŠŸèƒ½å¤±è´¥: {embed_response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {embed_response.text}")
            return False
            
    except Exception as e:
        print(f"    åµŒå…¥æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def save_remote_config(base_url, code_model, embed_model, fix_model):
    """ä¿å­˜è¿œç¨‹é…ç½®"""
    print(f"\n ä¿å­˜è¿œç¨‹é…ç½®...")
    
    # è®¾ç½®é…ç½®
    remote_config.set_remote_config(
        base_url=base_url,
        embedding_model=embed_model,
        code_model=code_model,
        fix_model=fix_model
    )
    
    # æ˜¾ç¤ºé…ç½®
    print(f"\n æœ€ç»ˆé…ç½®:")
    remote_config.print_config()
    
    # ä¿å­˜ç¯å¢ƒå˜é‡æ–‡ä»¶
    config_content = f'''# è¿œç¨‹Ollamaé…ç½®æ–‡ä»¶
# ä½¿ç”¨æ–¹æ³•: source remote_ollama_env.sh

export OLLAMA_BASE_URL="{base_url}"
export OLLAMA_CODE_MODEL="{code_model}"
export OLLAMA_EMBEDDING_MODEL="{embed_model}"
export OLLAMA_FIX_MODEL="{fix_model}"

echo " è¿œç¨‹Ollamaç¯å¢ƒå˜é‡å·²è®¾ç½®"
echo "   æœåŠ¡å™¨: $OLLAMA_BASE_URL"
echo "   ä»£ç æ¨¡å‹: $OLLAMA_CODE_MODEL"
echo "   åµŒå…¥æ¨¡å‹: $OLLAMA_EMBEDDING_MODEL"
echo "   ä¿®å¤æ¨¡å‹: $OLLAMA_FIX_MODEL"
'''
    
    env_file = Path("remote_ollama_env.sh")
    env_file.write_text(config_content)
    
    print(f" é…ç½®å·²ä¿å­˜åˆ°: {env_file}")
    
    # ä¿å­˜Pythoné…ç½®æ–‡ä»¶
    py_config_content = f'''# è¿œç¨‹Ollama Pythoné…ç½®
import os

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OLLAMA_BASE_URL"] = "{base_url}"
os.environ["OLLAMA_CODE_MODEL"] = "{code_model}"
os.environ["OLLAMA_EMBEDDING_MODEL"] = "{embed_model}"
os.environ["OLLAMA_FIX_MODEL"] = "{fix_model}"

print("è¿œç¨‹Ollamaé…ç½®å·²åŠ è½½")
'''
    
    py_config_file = Path("remote_config.py")
    py_config_file.write_text(py_config_content)
    
    print(f" Pythoné…ç½®å·²ä¿å­˜åˆ°: {py_config_file}")

def provide_usage_instructions():
    """æä¾›ä½¿ç”¨è¯´æ˜"""
    print(f"\n ä½¿ç”¨è¯´æ˜")
    print("="*50)
    
    print("æ–¹æ³•1: ä½¿ç”¨Shellç¯å¢ƒå˜é‡")
    print("   source remote_ollama_env.sh")
    print("   python test_java_only.py")
    
    print("\næ–¹æ³•2: ä½¿ç”¨Pythoné…ç½®æ–‡ä»¶")
    print("   åœ¨è„šæœ¬å¼€å¤´æ·»åŠ : import remote_config")
    print("   python test_java_only.py")
    
    print("\næ–¹æ³•3: æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡")
    print("   export OLLAMA_BASE_URL=\"...\"")
    print("   export OLLAMA_CODE_MODEL=\"...\"")
    print("   export OLLAMA_EMBEDDING_MODEL=\"...\"")
    print("   python test_java_only.py")
    
    print(f"\n ä¸‹ä¸€æ­¥:")
    print("1. source remote_ollama_env.sh")
    print("2. python test_java_only.py")
    print("3. å¼€å§‹RAGç³»ç»Ÿå¼€å‘")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ è¿œç¨‹Ollamaä¸“é¡¹é…ç½®åŠ©æ‰‹")
    print("="*60)
    print("é€‚ç”¨äº: æœ¬åœ°å¼€å‘ + è¿œç¨‹OllamaæœåŠ¡å™¨æ¶æ„")
    print("="*60)
    
    # 1. è¾“å…¥è¿œç¨‹é…ç½®
    base_url = input_remote_config()
    if not base_url:
        return False
    
    # 2. æ£€æµ‹è¿œç¨‹æ¨¡å‹
    models_info = detect_remote_models(base_url)
    if not models_info:
        return False
    
    # 3. é€‰æ‹©æ¨¡å‹
    code_model, embed_model, fix_model = select_models(models_info)
    
    print(f"\n æ‚¨çš„é€‰æ‹©:")
    print(f"   ğŸŒ æœåŠ¡å™¨: {base_url}")
    print(f"   ğŸ’» ä»£ç ç”Ÿæˆ: {code_model}")
    print(f"   ğŸ”¤ åµŒå…¥æ¨¡å‹: {embed_model}")
    print(f"    ä¿®å¤æ¨¡å‹: {fix_model}")
    
    # 4. æµ‹è¯•æ¨¡å‹åŠŸèƒ½
    if test_remote_models(base_url, code_model, embed_model):
        print(f"\n è¿œç¨‹æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
        
        # 5. ä¿å­˜é…ç½®
        save_remote_config(base_url, code_model, embed_model, fix_model)
        
        # 6. æä¾›ä½¿ç”¨è¯´æ˜
        provide_usage_instructions()
        
        return True
    else:
        print(f"\n è¿œç¨‹æ¨¡å‹æµ‹è¯•å¤±è´¥")
        print("å»ºè®®æ£€æŸ¥:")
        print("1. æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
        print("2. è¿œç¨‹æœåŠ¡å™¨ä¸Šæ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
        
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
